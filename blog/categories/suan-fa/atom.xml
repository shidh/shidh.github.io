<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 算法 | 搜不狗]]></title>
  <link href="http://www.sobugou.com/blog/categories/suan-fa/atom.xml" rel="self"/>
  <link href="http://www.sobugou.com/"/>
  <updated>2015-09-19T11:39:17+02:00</updated>
  <id>http://www.sobugou.com/</id>
  <author>
    <name><![CDATA[Allen Shi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[常见排序算法总结]]></title>
    <link href="http://www.sobugou.com/blog/2015/09/02/chang-jian-sortingsuan-fa-zong-jie/"/>
    <updated>2015-09-02T11:00:43+02:00</updated>
    <id>http://www.sobugou.com/blog/2015/09/02/chang-jian-sortingsuan-fa-zong-jie</id>
    <content type="html"><![CDATA[<h2>比较排序算法</h2>

<p>比较排序如其名，需要通过比较两个元素的大小来确定他们的前后序列。</p>

<p><img src="/images/2015-09/comparisonSorts.jpg" alt="Comparison Sorting" /></p>

<ul>
<li><strong>性能限制和优势</strong></li>
</ul>


<p>比较排序有很多性能上的根本限制。在最差情况下，<strong>任何一种比较排序至少需要O(nlogn)比较操作</strong>.这是比较操作所获的信息有限所导致的，或者说是全序集的模糊代数结构所导致的。从这个意义上讲，归并排序，堆排序在他们必须比较的次数上是渐进最优的。 因此比较排序的最好情况为nlogn的复杂度。</p>

<p>不过，<strong>比较排序在控制比较函数方面有显著优势</strong>，因此比较排序能对各种数据类型进行排序，并且可以很好地控制一个序列如何被排序。例如，如果倒置比较函数的输出结果可以让排序结果倒置。或者可以构建一个按字典顺序排序的比较函数，这样排序的结果就是按字典顺序的。</p>

<p>比较排序可以更好地适应复杂顺序，例如浮点数。并且，一旦比较函数完成，任何比较算法都可以不经修改地使用；而<strong>非比较排序对数据类型的要求更严格。</strong> 这种灵活性和上述比较排序在现代计算机的执行效率一起导致了比较排序被更多地应用在了大多数实际工作中。</p>

<h3>原始输入数据情况：</h3>

<ul>
<li>平均情况：Random</li>
</ul>


<blockquote><p>A random initial order is often used to evaluate sorting algorithms in order to elucidate the &ldquo;typical&rdquo; case</p></blockquote>

<ul>
<li>最好情况 Sorting nearly sorted</li>
</ul>


<blockquote><p>It is quite common in practice. Some observations:</p>

<p>Insertion sort is the clear winner on this initial condition.
Bubble sort is fast, but insertion sort has lower overhead.
Shell sort is fast because it is based on insertion sort.
Merge sort, heap sort, and quick sort do not adapt to nearly sorted data.</p></blockquote>

<ul>
<li>最坏情况 Reversed Initial Order</li>
</ul>


<blockquote><p>Sorting an array that is initially in reverse sorted order is an interesting case because it is common in practice and it brings out worse-case behavior for insertion sort, bubble sort, and shell sort.</p></blockquote>

<h3>冒泡排序 BubbleSort</h3>

<ul>
<li>性能分析</li>
</ul>


<p>时间复杂度O(n<sup>2</sup>), 空间复杂度O(1)， 稳定，因为存在两两比较，不存在跳跃。
最好是O(n), 最差，平均都是O(n<sup>2</sup>)</p>

<ul>
<li>步骤</li>
</ul>


<p>1 比较相邻的元素。如果第一个比第二个大，就交换他们两个。</p>

<p>2 对第0个到第n-1个数据做同样的工作。这时，最大的数就“浮”到了数组最后的位置上。</p>

<p>3 针对所有的元素重复以上的步骤，除了最后一个。</p>

<p>4 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</p>

<ul>
<li>核心代码</li>
</ul>


<pre><code class="Java">public class BubbleSort {
    public static void main(String[] args) {
        int[] number = {95,45,15,78,84,51,24,12};
        int temp = 0;
        for (int i = 0; i &lt; number.length - 1; i++){
            for (int j = 0; j &lt; number.length - 1 - i ; j++){
                if (number[j] &gt; number[j + 1]) {
                    temp = number[j];
                    number[j] = number[j + 1];
                    number[j + 1] = temp;
                } //if end
            }
            for(int k = 0; k &lt; number.length; k++){
                System.out.print(number[k] + " ");
            }
            System.out.println("loop:"+i);    
        }
    } //main end
} //BubbleSort end
</code></pre>

<blockquote><p>45 15 78 84 51 24 12 95 loop:0</p>

<p>15 45 78 51 24 12 84 95 loop:1</p>

<p>15 45 51 24 12 78 84 95 loop:2</p>

<p>15 45 24 12 51 78 84 95 loop:3</p>

<p>15 24 12 45 51 78 84 95 loop:4</p>

<p>15 12 24 45 51 78 84 95 loop:5</p>

<p>12 15 24 45 51 78 84 95 loop:6</p></blockquote>

<ul>
<li>延伸</li>
</ul>


<p>冒泡排序缺陷：</p>

<ul>
<li><p>在排序过程中，执行完当前的第i趟排序后，可能数据已全部排序完备，但是程序无法判断是否完成排序，会继续执行剩下的(n-1-i)趟排序。解决方法： 设置一个flag位, 如果一趟无元素交换，则 flag = 0; 以后再也不进入第二层循环。</p></li>
<li><p>当排序的数据比较多时排序的时间会明显延长，因为会比较 n*(n-1)/2次。</p></li>
</ul>


<blockquote><p>腾讯笔试题：线性表长度为10，在最坏的情况下，冒泡排序需要比较的次数为：40 42 44 45.</p>

<p>答案是45。</p></blockquote>

<p>Python实现的优化方案： <a href="https://github.com/wuchong/Algorithm-Interview/blob/master/Sort/python/BubbleSort.py">https://github.com/wuchong/Algorithm-Interview/blob/master/Sort/python/BubbleSort.py</a></p>

<ul>
<li><strong>排序所需的比较次数</strong></li>
</ul>


<p>当n是所需排序的元素个数时，比较排序所需的比较次数按nlog(n)比例增加。</p>

<h3>归并排序 MergeSort</h3>

<p>归并排序是采用<strong>分治法</strong>的一个非常典型的应用。归并排序的思想就是<strong>先递归分解数组</strong>，再<strong>合并数组</strong>。1945年由约翰·冯·诺伊曼首次提出。</p>

<p>先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。</p>

<p>再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。</p>

<p>归并排序的时间复杂度，合并耗费O(n)时间，而由<strong>完全二叉树的深度</strong>可知，整个归并排序需要进行logn次，因此，总的时间复杂度为 O(nlogn)，而且这是归并排序算法中最好、最坏、平均的时间性能。</p>

<p>由于归并排序在归并过程中需要与原始记录序列同样数量的存储空间存放归并结果 以及 递归时深度为 logn 的栈空间，因此空间复杂度为O(n+logn)。</p>

<p>另外，对代码进行仔细研究，发现 Merge 函数中有if (arr1[i] &lt; arr2[j]) 语句，这就说明它需要两两比较，不存在跳跃，因此归并排序是一种<strong>稳定</strong>的排序算法。</p>

<p>也就是说，归并排序是一种比较占用内存，但却效率高且稳定的算法。</p>

<p><img src="/images/2015-09/mergeSort.gif" alt="Merge Sort" /></p>

<ul>
<li>核心代码</li>
</ul>


<pre><code class="Java">private static int[] mergeSort(int[] arr){//归并排序 --递归
    if(arr.length==1){
        return arr;
    }
    int half = arr.length/2;
    int[] arr1 = new int[half];
    int[] arr2 = new int[arr.length-half];
    System.arraycopy(arr, 0, arr1, 0, arr1.length);
    System.arraycopy(arr, half, arr2, 0, arr2.length);
    arr1 = mergeSort(arr1);//递归调用，排序前半段arry[start...mid]
    arr2 = mergeSort(arr2);//递归调用，排序后半段arry[mid+1,end]
    return mergeArray(arr1,arr2); //归并上述两段有序数组。
}
private static int[] mergeArray(int[] arr1,int[] arr2){//归并排序子程序
    int[] result = new int[arr1.length+arr2.length];
    int i = 0;
    int j = 0;
    int k = 0;
    while(true){
        if(arr1[i] &lt; arr2[j]){
            result[k] = arr1[i];
            if(++i&gt;arr1.length-1){
                break;
            }
        }else{
            result[k] = arr2[j];
            if(++j&gt;arr2.length-1){
                break;
            }
        }
        k++;
    }
    for(;i&lt;arr1.length;i++){
        result[++k] = arr1[i];
    }
    for(;j&lt;arr2.length;j++){
        result[++k] = arr2[j];
    }
    return result;
}
</code></pre>

<h3>堆排序 HeapSort</h3>

<p>堆排序借助了堆这个数据结构，堆类似二叉树，又具有堆积的性质（<strong>子节点的关键值总小于（大于）父节点</strong>）。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。</p>

<h4>二叉堆具有以下性质：</h4>

<ul>
<li>父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。</li>
<li>每个节点的左右子树都是一个二叉堆（都是最大堆或最小堆）。</li>
</ul>


<h4>步骤：</h4>

<ol>
<li><p>构造最大堆（Build_Max_Heap）：若数组下标范围为0~n，考虑到单独一个元素是大根堆，则从下标n/2开始的元素均为大根堆。于是只要从n/2-1开始，向前依次构造大根堆，这样就能保证，构造到某个节点时，它的左右子树都已经是大根堆。 时间复杂度O(n)线性时间建堆。</p></li>
<li><p>堆排序（HeapSort）：由于堆是用数组模拟的。得到一个大根堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0&hellip;n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0&hellip;n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。</p></li>
<li><p>最大堆调整（Max_Heapify）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点 。从而保持堆的性质，时间复杂度O(logn)</p></li>
</ol>


<p>对于大数据的处理： 如果对100亿条数据选择Topk数据，选择快速排序好还是堆排序好？</p>

<p>答案是只能用堆排序。 <strong>堆排序只需要维护一个k大小的空间，即在内存开辟k大小的空间。</strong>而快速排序需要开辟能存储100亿条数据的空间，which is impossible.</p>

<ul>
<li>堆这种数据结构的很好的应用是 优先级队列，如作业调度。
最小堆排序动态过程参考这里<a href="http://www.benfrederickson.com/heap-visualization/">http://www.benfrederickson.com/heap-visualization/</a></li>
</ul>


<h3>快速排序 QuickSort</h3>

<h2>非比较排序算法</h2>

<p><img src="/images/2015-09/non-comparisonSorts.jpg" alt="Non-comparison Sorting" /></p>

<p>非比较排序算法通过非比较操作能在O(n)完成，这使他们能够回避O(nlogn)这个下界（假设元素是定值）。</p>

<h3>桶排序 BucketSort</h3>

<h3>计数排序 CountingSort</h3>

<h3>基数排序 RadixSort</h3>

<h2>stability</h2>

<blockquote><p>A sorting algorithm is stable if whenever there are two records R and S with the same key, and R appears before S in the original list, then R will always appear before S in the sorted list.</p></blockquote>

<p>一个典型的例子就是排序扑克牌，在排序前的扑克序列里，梅花4在红桃4前面，排序后顺序不变。如果是non-stable sort，排序后顺序调换。</p>

<ul>
<li><p>选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，</p></li>
<li><p>冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法。</p></li>
<li><p>常用时间复杂度的大小关系：</p>

<pre><code>O(1)&lt;O(logn)&lt;O(n)&lt;O(nlogn)&lt;O(n2)&lt;O(n3)&lt;O(2n)&lt;O(n!)&lt;O(nn)
</code></pre></li>
</ul>


<h2>参考链接</h2>

<p><a href="http://segmentfault.com/a/1190000002595152#articleHeader30">http://segmentfault.com/a/1190000002595152#articleHeader30</a></p>

<p><a href="http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/">http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/</a></p>

<h3>一个展示排序过程的视频：</h3>

<p><a href="http://v.youku.com/v_show/id_XNTkwNzI5OTIw.html">http://v.youku.com/v_show/id_XNTkwNzI5OTIw.html</a></p>

<h3>一个展示排序网站：</h3>

<p><a href="http://www.sorting-algorithms.com/">http://www.sorting-algorithms.com/</a></p>

<p>当你打开先点击网页上方的Problem Size，选择一个尺寸，20，30，40还是50，于是你就可以看到下面整个大表中有图片显示出来了。如下所示：</p>

<p><img src="/images/2015-09/sort.jpg" title="排序示例" alt="Sorting" /></p>

<p>其中，</p>

<ul>
<li><p><strong>列。</strong>是代表每一个排序算法，有“插入”“选择”“冒泡”“Shell”，“合并Merge”，“堆排序”，“快速排序”，“快速3排序”。单击每个一算法的链接，你可以看到这个算法的详细解释，其中包括，算法的伪代码，算法的复杂度，相关的讨论，重点，以及该算法的相关参考文档。</p></li>
<li><p><strong>行。</strong>是不同的数据样本，第一个是“随机样本”，第二个是“几乎排好序的样本”，第三个是“最差的样本（反序）”，第四个是“有一些相同项的样本”。这些样本在不同的算法上都会有不同的表现。</p></li>
<li><p><strong>单元格。</strong>每个单元格都是一个图片。简单的用鼠标单击一下每个图片，可以动画地演示算法整个过程。其中两个小红箭头表示了正在需要“交换顺序的数据”。</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[[转]HashMap实例：求Top K]]></title>
    <link href="http://www.sobugou.com/blog/2015/09/01/hashmapshi-li-:qiu-top-k/"/>
    <updated>2015-09-01T19:26:45+02:00</updated>
    <id>http://www.sobugou.com/blog/2015/09/01/hashmapshi-li-:qiu-top-k</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>百度面试题：</p>

<p> 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
    假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。</p>

<h2>必备知识：</h2>

<p>什么是哈希表？</p>

<blockquote><p>哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。</p>

<p>哈希表hashtable(key，value) 的做法其实很简单，就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。</p>

<p>而当使用哈希表进行查询的时候，就是再次使用哈希函数将key转换为对应的数组下标，并定位到该空间获取value，如此一来，就可以充分利用到数组的定位性能进行数据定位（文章第二、三部分，会针对Hash表详细阐述）。</p></blockquote>

<h2>问题解析：</h2>

<p>要统计最热门查询，首先就是要统计每个Query出现的次数，然后根据统计结果，找出Top 10。所以我们可以基于这个思路分两步来设计该算法。
    即，此问题的解决分为以下俩个步骤：<!--more--></p>

<h3>第一步：Query统计</h3>

<p>Query统计有以下俩个方法，可供选择：</p>

<ul>
<li><p>直接排序法</p>

<p>  首先我们最先想到的的算法就是排序了，首先对这个日志里面的所有Query都进行排序，然后再遍历排好序的Query，统计每个Query出现的次数了。</p>

<p>  但是题目中有明确要求，那就是内存不能超过1G，一千万条记录，每条记录是255Byte，很显然要占据2.375G内存，这个条件就不满足要求了。</p>

<p>  让我们回忆一下数据结构课程上的内容，当数据量比较大而且内存无法装下的时候，我们可以采用外排序的方法来进行排序，这里我们可以采用归并排序，因为归并排序有一个比较好的时间复杂度O(NlgN)。</p>

<p>  排完序之后我们再对已经有序的Query文件进行遍历，统计每个Query出现的次数，再次写入文件中。</p>

<p>  综合分析一下，排序的时间复杂度是O(NlgN)，而遍历的时间复杂度是O(N)，因此该算法的总体时间复杂度就是O(N+NlgN)=O（NlgN）。</p></li>
<li><p>Hash Table法</p>

<p>  在第1个方法中，我们采用了排序的办法来统计每个Query出现的次数，时间复杂度是NlgN，那么能不能有更好的方法来存储，而时间复杂度更低呢？</p>

<p>  题目中说明了，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去，而现在只是需要一个合适的数据结构，在这里，Hash Table绝对是我们优先的选择，因为Hash Table的查询速度非常的快，几乎是O(1)的时间复杂度。</p>

<p>  那么，我们的算法就有了：维护一个Key为Query字串，Value为该Query出现次数的HashTable，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内完成了对该海量数据的处理。</p>

<p>  本方法相比算法1：在时间复杂度上提高了一个数量级，为O（N），但不仅仅是时间复杂度上的优化，该方法只需要IO数据文件一次，而算法1的IO次数较多的，因此该算法2比算法1在工程上有更好的可操作性。</p></li>
</ul>


<h3>第二步：找出Top 10</h3>

<p><strong>这部分经常单独作为一个面试题出现</strong></p>

<ul>
<li><p>算法一：普通排序
  我想对于排序算法大家都已经不陌生了，这里不在赘述，我们要注意的是排序算法的时间复杂度是NlgN，在本题目中，三百万条记录，用1G内存是可以存下的。</p></li>
<li><p>算法二：部分排序
  题目要求是求出Top 10，因此我们没有必要对所有的Query都进行排序，我们只需要维护一个10个大小的数组，初始化放入10个Query，按照每个Query的统计次数由大到小排序，然后遍历这300万条记录，每读一条记录就和数组最后一个Query对比，如果小于这个Query，那么继续遍历，否则，将数组中最后一条数据淘汰，加入当前的Query。最后当所有的数据都遍历完毕之后，那么这个数组中的10个Query便是我们要找的Top10了。</p>

<p>  不难分析出，这样，算法的最坏时间复杂度是N*K， 其中K是指top多少。</p></li>
<li><p>算法三：堆
  在算法二中，我们已经将时间复杂度由NlogN优化到NK，不得不说这是一个比较大的改进了，可是有没有更好的办法呢？</p>

<p>  分析一下，在算法二中，每次比较完成之后，需要的操作复杂度都是K，因为要把元素插入到一个线性表之中，而且采用的是顺序比较。这里我们注意一下，该数组是有序的，一次我们每次查找的时候可以采用二分的方法查找，这样操作的复杂度就降到了logK，可是，随之而来的问题就是数据移动，因为移动数据次数增多了。不过，这个算法还是比算法二有了改进。</p>

<p>  基于以上的分析，我们想想，有没有一种既能快速查找，又能快速移动元素的数据结构呢？回答是肯定的，那就是堆。
  借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此到这里，我们的算法可以改进为这样，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。</p>

<p>  具体过程是，堆顶存放的是整个堆中最小的数，现在遍历N个数，把最先遍历到的k个数存放到最小堆中，并假设它们就是我们要找的最大的k个数，X1>X2&hellip;Xmin(堆顶)，而后遍历后续的N-K个数，一一与堆顶元素进行比较，如果遍历到的Xi大于堆顶元素Xmin，则把Xi放入堆中，而后更新整个堆，更新的时间复杂度为logK，如果Xi&lt;Xmin，则不更新堆，整个过程的复杂度为O(K)+O(（N-K）<em>logK)=O（N</em>logK）。</p></li>
</ul>


<p>（堆排序的3D动画演示可以参看此链接：<a href="http://www.benfrederickson.com/2013/10/10/heap-visualization.html">http://www.benfrederickson.com/2013/10/10/heap-visualization.html</a>）</p>

<p>   思想与上述算法二一致，只是算法在算法三，我们采用了最小堆这种数据结构代替数组，把查找目标元素的时间复杂度有O（K）降到了O（logK）。</p>

<p>   那么这样，采用堆数据结构，算法三，最终的时间复杂度就降到了N‘logK，和算法二相比，又有了比较大的改进。</p>

<h2>总结：</h2>

<p>   至此，算法就完全结束了，经过上述第一步、
   先用Hash表统计每个Query出现的次数，O（N）；</p>

<p>   然后第二步、采用堆数据结构找出Top 10，N*O（logK）。</p>

<p>   所以，我们最终的时间复杂度是：O（N） + N&#8217;*O（logK）。（N为1000万，N’为300万）。</p>

<p>   此外，还可以看下此文第二部分的第二题：<a href="http://blog.csdn.net/v_july_v/article/details/7382693">http://blog.csdn.net/v_july_v/article/details/7382693</a>。</p>
]]></content>
  </entry>
  
</feed>
