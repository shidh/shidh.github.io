<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hashmap | 搜不狗]]></title>
  <link href="http://www.sobugou.com/blog/categories/hashmap/atom.xml" rel="self"/>
  <link href="http://www.sobugou.com/"/>
  <updated>2015-09-22T11:41:53+02:00</updated>
  <id>http://www.sobugou.com/</id>
  <author>
    <name><![CDATA[Allen Shi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[[转]HashMap实例：求Top K]]></title>
    <link href="http://www.sobugou.com/blog/2015/09/01/hashmapshi-li-:qiu-top-k/"/>
    <updated>2015-09-01T19:26:45+02:00</updated>
    <id>http://www.sobugou.com/blog/2015/09/01/hashmapshi-li-:qiu-top-k</id>
    <content type="html"><![CDATA[<h2>问题描述</h2>

<p>百度面试题：</p>

<p> 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
    假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。），请你统计最热门的10个查询串，要求使用的内存不能超过1G。</p>

<h2>必备知识：</h2>

<p>什么是哈希表？</p>

<blockquote><p>哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。</p>

<p>哈希表hashtable(key，value) 的做法其实很简单，就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。</p>

<p>而当使用哈希表进行查询的时候，就是再次使用哈希函数将key转换为对应的数组下标，并定位到该空间获取value，如此一来，就可以充分利用到数组的定位性能进行数据定位（文章第二、三部分，会针对Hash表详细阐述）。</p></blockquote>

<h2>问题解析：</h2>

<p>要统计最热门查询，首先就是要统计每个Query出现的次数，然后根据统计结果，找出Top 10。所以我们可以基于这个思路分两步来设计该算法。
    即，此问题的解决分为以下俩个步骤：</p>

<!--more-->


<h3>第一步：Query统计</h3>

<p>Query统计有以下俩个方法，可供选择：</p>

<ul>
<li><p>直接排序法</p>

<p>  首先我们最先想到的的算法就是排序了，首先对这个日志里面的所有Query都进行排序，然后再遍历排好序的Query，统计每个Query出现的次数了。</p>

<p>  但是题目中有明确要求，那就是内存不能超过1G，一千万条记录，每条记录是255Byte，很显然要占据2.375G内存，这个条件就不满足要求了。</p>

<p>  让我们回忆一下数据结构课程上的内容，当数据量比较大而且内存无法装下的时候，我们可以采用外排序的方法来进行排序，这里我们可以采用归并排序，因为归并排序有一个比较好的时间复杂度O(NlgN)。</p>

<p>  排完序之后我们再对已经有序的Query文件进行遍历，统计每个Query出现的次数，再次写入文件中。</p>

<p>  综合分析一下，排序的时间复杂度是O(NlgN)，而遍历的时间复杂度是O(N)，因此该算法的总体时间复杂度就是O(N+NlgN)=O（NlgN）。</p></li>
<li><p>Hash Table法</p>

<p>  在第1个方法中，我们采用了排序的办法来统计每个Query出现的次数，时间复杂度是NlgN，那么能不能有更好的方法来存储，而时间复杂度更低呢？</p>

<p>  题目中说明了，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去，而现在只是需要一个合适的数据结构，在这里，Hash Table绝对是我们优先的选择，因为Hash Table的查询速度非常的快，几乎是O(1)的时间复杂度。</p>

<p>  那么，我们的算法就有了：维护一个Key为Query字串，Value为该Query出现次数的HashTable，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内完成了对该海量数据的处理。</p>

<p>  本方法相比算法1：在时间复杂度上提高了一个数量级，为O（N），但不仅仅是时间复杂度上的优化，该方法只需要IO数据文件一次，而算法1的IO次数较多的，因此该算法2比算法1在工程上有更好的可操作性。</p></li>
</ul>


<h3>第二步：找出Top 10</h3>

<p><strong>这部分经常单独作为一个面试题出现</strong></p>

<ul>
<li><p>算法一：普通排序
  我想对于排序算法大家都已经不陌生了，这里不在赘述，我们要注意的是排序算法的时间复杂度是NlgN，在本题目中，三百万条记录，用1G内存是可以存下的。</p></li>
<li><p>算法二：部分排序
  题目要求是求出Top 10，因此我们没有必要对所有的Query都进行排序，我们只需要维护一个10个大小的数组，初始化放入10个Query，按照每个Query的统计次数由大到小排序，然后遍历这300万条记录，每读一条记录就和数组最后一个Query对比，如果小于这个Query，那么继续遍历，否则，将数组中最后一条数据淘汰，加入当前的Query。最后当所有的数据都遍历完毕之后，那么这个数组中的10个Query便是我们要找的Top10了。</p>

<p>  不难分析出，这样，算法的最坏时间复杂度是N*K， 其中K是指top多少。</p></li>
<li><p>算法三：堆
  在算法二中，我们已经将时间复杂度由NlogN优化到NK，不得不说这是一个比较大的改进了，可是有没有更好的办法呢？</p>

<p>  分析一下，在算法二中，每次比较完成之后，需要的操作复杂度都是K，因为要把元素插入到一个线性表之中，而且采用的是顺序比较。这里我们注意一下，该数组是有序的，一次我们每次查找的时候可以采用二分的方法查找，这样操作的复杂度就降到了logK，可是，随之而来的问题就是数据移动，因为移动数据次数增多了。不过，这个算法还是比算法二有了改进。</p>

<p>  基于以上的分析，我们想想，有没有一种既能快速查找，又能快速移动元素的数据结构呢？回答是肯定的，那就是堆。
  借助堆结构，我们可以在log量级的时间内查找和调整/移动。因此到这里，我们的算法可以改进为这样，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。</p>

<p>  具体过程是，堆顶存放的是整个堆中最小的数，现在遍历N个数，把最先遍历到的k个数存放到最小堆中，并假设它们就是我们要找的最大的k个数，X1>X2&hellip;Xmin(堆顶)，而后遍历后续的N-K个数，一一与堆顶元素进行比较，如果遍历到的Xi大于堆顶元素Xmin，则把Xi放入堆中，而后更新整个堆，更新的时间复杂度为logK，如果Xi&lt;Xmin，则不更新堆，整个过程的复杂度为O(K)+O(（N-K）<em>logK)=O（N</em>logK）。</p></li>
</ul>


<p>（堆排序的3D动画演示可以参看此链接：<a href="http://www.benfrederickson.com/2013/10/10/heap-visualization.html">http://www.benfrederickson.com/2013/10/10/heap-visualization.html</a>）</p>

<p>   思想与上述算法二一致，只是算法在算法三，我们采用了最小堆这种数据结构代替数组，把查找目标元素的时间复杂度有O（K）降到了O（logK）。</p>

<p>   那么这样，采用堆数据结构，算法三，最终的时间复杂度就降到了N‘logK，和算法二相比，又有了比较大的改进。</p>

<h2>总结：</h2>

<p>   至此，算法就完全结束了，经过上述第一步、
   先用Hash表统计每个Query出现的次数，O（N）；</p>

<p>   然后第二步、采用堆数据结构找出Top 10，N*O（logK）。</p>

<p>   所以，我们最终的时间复杂度是：O（N） + N&#8217;*O（logK）。（N为1000万，N’为300万）。</p>

<p>   此外，还可以看下此文第二部分的第二题：<a href="http://blog.csdn.net/v_july_v/article/details/7382693">http://blog.csdn.net/v_july_v/article/details/7382693</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[HashMap的原理总结]]></title>
    <link href="http://www.sobugou.com/blog/2015/08/28/hashmapde-yuan-li-zong-jie/"/>
    <updated>2015-08-28T17:59:57+02:00</updated>
    <id>http://www.sobugou.com/blog/2015/08/28/hashmapde-yuan-li-zong-jie</id>
    <content type="html"><![CDATA[<p>我们知道HashMap拥有高读取性能，the hash-map has O(1) access with <strong>high probability</strong> （注意是最理想情况是O(1)，但是相比O(n)更接近O(1)）。高读取性能数据结构背后具体是怎么实现的呢，这篇笔记就一起来总结下。</p>

<h2>缘起</h2>

<p>数据结构中有数组和链表来实现对数据的存储，但这两者基本上是两个极端。</p>

<h3>数组</h3>

<p>数组存储区间是连续的，占用内存严重，故空间复杂的很大。但数组的二分查找时间复杂度小，为O(1)；数组的特点是：<strong>寻址容易</strong>，插入和删除困难；</p>

<h3>链表</h3>

<p>链表存储区间离散，占用内存比较宽松，故空间复杂度很小，但时间复杂度很大，达O（N）。链表的特点是：寻址困难，<strong>插入和删除容易</strong>。</p>

<h3>哈希表</h3>

<p>那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？答案是肯定的，这就是我们要提起的哈希表。哈希表（(Hash table）既满足了数据的查找方便，同时不占用太多的内容空间，使用也十分方便。　　</p>

<p>在一个随机性良好的hash函数的情况下，hash模型基本和以下问题一致：
<strong>把k个球随机放入n个盒子，碰撞次数定义为有球的总数k减去有球的盒的个数（当然，不同存储结构有所不同）</strong>。</p>

<p>碰撞的概率还跟当前空间中已经被映射的点的数量有关，存入hash的元素越多，碰撞概率就越大。给定k个球，随机放入n个盒子，在相同盒子里面的球的期望个数也会增大。</p>

<h2>hash方法</h2>

<p>元素特征转变为数组下标的方法就是散列法。散列法当然不止一种，下面列出三种比较常用的：</p>

<p>1, 除法散列法
最直观的一种，上图使用的就是这种散列法，公式：
      index = value % 16
学过汇编的都知道，求模数其实是通过一个除法运算得到的，所以叫“除法散列法”。</p>

<p>2, 平方散列法
求index是非常频繁的操作，而乘法的运算要比除法来得省时（对现在的CPU来说，估计我们感觉不出来），所以我们考虑把除法换成乘法和一个位移操作。公式：</p>

<pre><code>index = (value * value) &gt;&gt; 28   （右移，除以2^28。记法：左移变大，是乘。右移变小，是除。）
</code></pre>

<p>如果数值分配比较均匀的话这种方法能得到不错的结果，但我上面画的那个图的各个元素的值算出来的index都是0——非常失败。也许你还有个问题，value如果很大，value * value不会溢出吗？答案是会的，但我们这个乘法不关心溢出，因为我们根本不是为了获取相乘结果，而是为了获取index。</p>

<p>3, 斐波那契（Fibonacci）散列法</p>

<p>平方散列法的缺点是显而易见的，所以我们能不能找出一个理想的乘数，而不是拿value本身当作乘数呢？答案是肯定的。</p>

<ul>
<li>对于16位整数而言，这个乘数是40503</li>
<li>对于32位整数而言，这个乘数是2654435769</li>
<li>对于64位整数而言，这个乘数是11400714819323198485</li>
</ul>


<p>这几个“理想乘数”是如何得出来的呢？这跟一个法则有关，叫黄金分割法则，而描述黄金分割法则的最经典表达式无疑就是著名的斐波那契数列，即如此形式的序列：0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610， 987, 1597, 2584, 4181, 6765, 10946，…。另外，斐波那契数列的值和太阳系八大行星的轨道半径的比例出奇吻合。</p>

<p>对我们常见的32位整数而言，公式：</p>

<pre><code>index = (value * 2654435769) &gt;&gt; 28
</code></pre>

<h2>hashcode() and equals() 方法</h2>

<p>由于HashMap的实现又依赖于hashcode() and equals()方法，先根据一个博客来整理下这两个继承于Object的方法。参考原文地址：<a href="http://www.java2blog.com/2014/02/hashcode-and-equals-method-in-java.html">http://www.java2blog.com/2014/02/hashcode-and-equals-method-in-java.html</a></p>

<p>These methods can be found in the Object class and hence available to all java classes. Using these two methods, an object can be stored or retrieved from a Hashtable, HashMap or HashSet.</p>

<ol>
<li><strong>hashcode():</strong>

<blockquote><p>You might know if you put entry in HashMap, first hashcode is calculated and this hashcode used to find bucket(index) where this entry will get stored in hashMap.You can read more at How hashMap works in java. What if you don&rsquo;t override hashcode method, it will return integer representation of memory address.
如果不重写的话，hashcode方法会返回类实例的内存地址的整形值。</p></blockquote></li>
</ol>


<p> Country类重写例子：</p>

<pre><code class="Java">@Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + ((name == null) ? 0 : name.hashCode());
        return result;
    }
</code></pre>

<ol>
<li><strong>equals():</strong>

<blockquote><p>The equals method implements an equivalence relation on non-null object references.
Read more at <a href="http://www.java2blog.com/2014/02/hashcode-and-equals-method-in-java.html#dXUX4kIP1gRjcrGt.99">http://www.java2blog.com/2014/02/hashcode-and-equals-method-in-java.html#dXUX4kIP1gRjcrGt.99</a> You have to override equals method, when you want to define equality between two object. If you don&rsquo;t override this method, it will check for reference equality(==) i.e. if tow reference refers to same object or not.</p></blockquote></li>
</ol>


<p>  如果想比较两个对象，就必须重写equals方法。否则这个方法默认是比较实例对象的堆引用，等同于 “==” 必然就会导致不同。所以可以推测String类一定重写了equals方法。</p>

<p> Country类重写例子：</p>

<pre><code class="Java">  @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        Country other = (Country) obj;
        if (name == null) {
            if (other.name != null)
                return false;
        } else if (!name.equals(other.name))
            return false;
        return true;
    }
</code></pre>

<h3>Key points to remember:</h3>

<blockquote><ul>
<li>If you are overriding equals method then you should override hashcode() also.</li>
<li>If two objects are equal then they must have same hashcode.</li>
<li>If two objects have same hashcode then they may or may not be equal</li>
<li>Always use same attributes to generate equals and hashcode as in our case we have used name.</li>
</ul>
</blockquote>

<p>总结来说，两个对象相等他们一定拥有相同的hashcode，但是相同的邀请码并不能说对象也相等。</p>

<h2>HashMap的结构Java实现</h2>

<p>在java中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。</p>

<p><img src="/images/2015-09/hashMap.jpg" title="HashMap在Java中结构" alt="HashMap" /></p>

<blockquote><p>Basically, a hash table is an array containing all of the keys to search on. The position of each key in the array is determined by the <em>hash function</em>, which can be any function which always maps the same input to the same output.</p></blockquote>

<p>哈希表hashmap&lt;key, value>就是一个数组装着所有的key. 这些key的位置是通过Object类的<em>hash function</em>来判断的，<em>hash function</em>会把同样的输入映射到同样的输出。</p>

<blockquote><p>So when we insert something into the hash table, we use the hash function (let&rsquo;s call it h) to find the location where to put it, and put it there. Now we insert another thing, hashing and storing. And another. Each time we insert data, it takes O(1) time to insert it (since the hash function is O(1).</p></blockquote>

<p>插入时候性能是O(1)。</p>

<blockquote><p>Looking up data is the same. If we want to find a value, x, we have only to find out h(x), which tells us where x is located in the hash table. So we can look up any hash value in O(1) as well.</p></blockquote>

<p>查询也是O(1)。</p>

<blockquote><p>Now to the lie: The above is a very nice theory with one problem: what if we insert data and there is already something in that position of the array? There is nothing which guarantees that the hash function won&rsquo;t produce the same output for two different inputs (unless you have a perfect hash function, but those are tricky to produce). Therefore, when we insert we need to take one of two strategies:</p></blockquote>

<p>但是在显示中我们很难有完美的Hash函数保证没有碰撞的，即不同的输入hash后的输出一样。为了解决这个问题一般用下面两种方案：</p>

<ul>
<li>Store multiple values at each spot in the array (say, each array slot has a linked list). Now when you do a lookup, it is still O(1) to arrive at the correct place in the array, but potentially a linear search down a (hopefully short) linked list. This is called &ldquo;separate chaining&rdquo;.</li>
</ul>


<p>每个数组里面存一个linked list，当查询key的位置的时候还是O(1),但是可能会有碰撞的值，要在查找这个linked list。这个是最常用的一种方法—— 拉链法，我们可以理解为“链表的数组”。</p>

<p><img src="/images/2015-09/HashMap_LinkList.jpeg" title="HashMap在Java中结构" alt="HashMap" /></p>

<pre><code class="Java">
     //The table, resized as necessary. Length MUST Always be a power of two.

    transient Entry[] table;

    static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
        final K key;
        V value;
        Entry&lt;K,V&gt; next;
        final int hash;
    }
</code></pre>

<p>可以看出，Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有一个指向下一个元素的引用，这就构成了链表。</p>

<ul>
<li>If you find something is already there, hash again and find another location. Repeat until you find an empty spot, and put it there. The lookup procedure can follow the same rules to find the data. Now it&rsquo;s still O(1) to get to the first location, but there is a potentially (hopefully short) linear search to bounce around the table till you find the data you are after. This is called &ldquo;open addressing&rdquo;.</li>
</ul>


<p>领一种方法就不细分析，原理是如果hash碰撞了就再hash一下，意思是hash的hash来得到其他的地址。</p>

<p>Basically, both approaches are still mostly O(1) but with a hopefully-short linear sequence. We can assume for most purposes that it is O(1). If the hash table is getting too full, those linear searches can become longer and longer, and then it is time to &ldquo;re-hash&rdquo; which means to create a new hash table of a much bigger size and insert all the data back into it.</p>

<p>如果Hash表快满的时候，插入和查找性能就会变差，因为碰撞会变多。这个时候（假如默认数组是16长度，那么插满0.75*16=12的时候就触发）就要resize整个hash表，就是扩大数组，把原来的Entry都重新hash一遍。非常消耗性能。</p>

<h2>参考链接</h2>

<p><a href="http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/java/util/HashMap.java?av=f">http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7u40-b43/java/util/HashMap.java?av=f</a></p>

<p><a href="http://docs.oracle.com/javase/7/docs/api/java/util/HashMap.html">http://docs.oracle.com/javase/7/docs/api/java/util/HashMap.html</a></p>

<p><a href="http://stackoverflow.com/questions/4363539/how-does-hashing-have-an-o1-search-time">http://stackoverflow.com/questions/4363539/how-does-hashing-have-an-o1-search-time</a></p>

<p><a href="http://zhangshixi.iteye.com/blog/672697">http://zhangshixi.iteye.com/blog/672697</a></p>

<p><a href="http://blog.csdn.net/vking_wang/article/details/14166593">http://blog.csdn.net/vking_wang/article/details/14166593</a></p>
]]></content>
  </entry>
  
</feed>
